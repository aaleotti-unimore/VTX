\chapter{Progetto}
\label{progetto}

In questo capitolo si propone il progetto realizzato per raggiungere gli obiettivi preposti: si è partiti dalla realizzazione di un classificatore basato su \textit{Random Forest} per poi passare ad una versione più elaborata, utilizzando una rete neurale. Il passo successivo ha riguardato la creazione di una \textit{Generative Adversarial Network} a partire da un Autoencoder.  


\section{Classificatore Random Forest}
\label{randomforest}
La prima fase di questo studio è stata quella di implementare un classificatore in grado di separare efficacemente domini DGA da domini non malevoli basandosi unicamente sulle caratteristiche linguistiche dei domini: infatti, ad un esame preliminare, i domini DGA presentano caratteristiche ben differenti da semplici frasi o parole che solitamente compongono i domini reali.

Si è scelto di utilizzare Random Forest in quanto ritenuto il più adatto al caso in esame. L'algoritmo è stato inoltre messo a confronto con \textit{Support Vector Machine} e \textit{Naive-Bayes}.

All'interno del classificatore \textit{Random Forest} \cite{randomforest}, ogni albero dell'insieme è costruito a partire da un campione estratto con sostituzione dal \textit{training set}. In aggiunta, al momento della divisione del nodo durante la costruzione di un albero, la divisione scelta non è più la migliore soluzione tra tutte le \textit{features}. Al suo posto, la divisone che viene scelta è la migliore divisione all'interno di un \textit{subset} casuale tra tutte le \textit{features}. Come risultato di questa casualità, il \textit{bias} della foresta di solito aumenta leggermente (rispetto al \textit{bias} di un singolo albero non casuale) ma, a causa della media, la sua varianza diminuisce, di solito compensando l'aumento di \textit{bias}, quindi dando un modello generale migliore.

\subsection{Dataset}
\label{randomforestinput}
I \textit{dataset} di \textit{training} e \textit{testing} sono stati ricavati due fonti differenti: per quel che riguarda i domini reali si è fatto riferimento alla classifica dei domini più visitati al mondo fornita da \textit{Alexa Internet Inc.} \cite{amazon:alexa} , per un totale di 1 milione di siti realmente esistenti; mentre grazie al repository fornito da \cite{github:dgarepo} è stato possibile ottenere un \textit{dataset} esaustivo di esempi \textit{DGA} da diverse famiglie di \textit{malware}.

A partire da tale dataset combinato si è proceduto alla creazione di un classificatore binario che fosse in grado di distinguere domini reali da domini generati algoritmicamente. 

Il passo seguente  stato creare una serie di \textit{features} che fossero in grado di descrivere le caratteristiche linguistiche dei domini presi in esame. Per raggiungere tale obiettivo si è fatto riferimento a ricerche già esistenti. Di seguito viene illustrato l'insieme di tali \textit{features}:

\subsection{Features}
\label{randomforestinterno}

\begin{itemize}
\item Meaningful Characters Ratio. Models the ratio of characters of the string p that comprise a meaningful word. Low values indicate automatic algorithms. Specifically, we split p into n meaningful subwords wi of at least 3 symbols: $|wi| >= 3$, leaving out as few symbols as possible: $R(d) = R(p) = max((sum from i=1 to n) |wi|)/|p|.$
    If p = facebook, $R(p) = (|face| + |book|)/8 = 1$, the prefix is fully composed of meaningful words, whereas p = pub03str, $R(p) = (|pub|)/8 = 0.375$.
    
\item n-gram Normality Score: This class of features captures the pronounceability of a domain name. The more permissible the combinations of phonemes, the more pronounceable a word is. Domains with a low number of such combinations are likely DGA-generated.
        We calculate this class of features by extracting the n-grams of p, which are the substrings of p of length n {1, 2, 3}, and counting their occurrences in the (English) language dictionary.
        The features are thus parametric to $n: Sn(d) = Sn(p) := ((sum of n-gram t in p) count(t))/(|p|-n+1)$, where count(t) are the occurrences of the n-gram t in the dictionary L
\end{itemize}



\subsection{Output}
\label{randomforestoutput}

\section{Classificatore Neurale}
\label{classificatorenn}

\subsection{Input}
\label{classificatorenninput}

\subsection{Composizione Interna}
\label{classificatorenninterno}

\subsection{Output}
\label{classificatorennoutput}

\section{Realizzazione Adversarial Learning}
\label{adv}

\subsection{Input}
\label{advinput}

\subsection{Composizione Interna}
\label{advinterno}

\subsection{Output}
\label{advoutput}

