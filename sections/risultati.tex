\chapter{Risultati}
\label{risultati}
In questo capitolo si presentano i risultati della fase sperimentale effettuata su tutti i sistemi mostrati precedentemente: classificatore Machine Learning, classificatore neurale, Autoencoder e Generative Adversarial Network. Le metriche di valutazione utilizzate sono enunciate all'interno della sezione~\ref{metriche}. In sezione~\ref{res:crf} vengono mostrati i risultati sperimentali ottenuti dal classificatore Machine Learning, punto di partenza di questo studio. In sezione~\ref{ris:cnn} vengono mostrati i risultai sperimentali ottenuti dal classificatore neurale, evoluzione del classificatore Machine Learning, e le problematiche incontrate durante tale fase. In sezione~\ref{ris:autoenc} viene mostrata la fase sperimentale che ha coinvolto l'Autoencoder, durante la quale si sono ottenuti i pesi utilizzati  come punto di partenza per la successiva fase di training della Generative Adversarial Network. All'interno dell'ultima sezione~\ref{ris:gan} sono mostrati i risultati ottenuti dal training della Generative Adversarial Network e la fase di affinamento degli iperparametri richiesta da quest'ultima.

\pagebreak
\section{Metriche di valutazione}
\label{metriche}
Le metriche di valutazione utilizzate per testare la qualità dei modelli sono state:

\begin{itemize}
\item \textbf{Precision}: il rapporto $\frac{t_p}{t_p+f_p}$ dove $t_p$ è il numero di veri positivi e $f_p$ il numero di falsi positivi. Intuitivamente è l'abilità del classificatore di non marcare come positivo un campione negativo.
\item \textbf{Recall}: il rapporto $\frac{t_p}{t_p+f_n}$  dove $f_n$ sono i falsi negativi. Intuitivamente è l'abilità del classificatore di trovare tutti i campioni positivi.
\item \textbf{F-Score}: è definito come la media armonica tra \textit{precision} e \textit{recall}: 
\[F_1 = 2 \cdot \frac{1}{\tfrac{1}{\mathrm{recall}} + \tfrac{1}{\mathrm{precision}}} = 2 \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{\mathrm{precision} + \mathrm{recall}}\]
\item \textbf{Area sottesa da Receiver Operating Characteristic}:  metodo grafico per la valutazione della qualità di un classificatore binario al variare della soglia di discriminazione. \`E creata graficando la frazione dei veri positivi rispetto ai campioni positivi ($tpr$ = True positive rate) contro la frazione dei falsi positivi rispetto ai campioni negativi ($fpr$ = False positive rate). L'area sottesa dalla curva ROC equivale alla probabilità che il classificatore predica un campione positivo casuale rispetto ad un campione negativo casuale. Formalmente è definita da:
\begin{align*}
A & = \int_{\infty}^{-\infty} \mbox{TPR}(T) \left(-\mbox{FPR}'(T)\right) \, dT \\
& = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} I(T'>T)f_1(T') f_0(T) \, dT' \, dT = P(X_1 > X_0)
\end{align*}

dove 
$X_{1}$ è il punteggio per un'istanza positiva e $X_{0}$ è il punteggio per un'istanza negativa, mentre $f_{0}$ e $f_{1}$ sono densità di probabilità che un campione sia negativo ($1$) o positivo ($0$)
\end{itemize}

\newpage
\section{Classificatore Machine Learning}
\label{res:crf}
In fase preliminare si è effettuato un confronto tra tre algoritmi di classificazione: 
\begin{itemize}
\item \textit{Random Forest}
\item \textit{SVC (C-Support Vector)}
\item \textit{Naive Bayes}. 
\end{itemize}
Il classificatore è stato inizialmente testato con le famiglie di malware elencate in tabella~\ref{tab:malware}, contro un subset di dimensione simile di domini provenienti dalla classifica Alexa Top 1M~\cite{amazon:alexa}. Il dataset così formato è stato separato in due parti disuguali: il 90\% è stato utilizzato come subset di training mentre il restante 10\% come subset di testing in maniera da evitare il fenomeno di \textit{overfitting}. 

\begin{table}[!bp]
    \centering
    \begin{tabular}[t]{l}
    \toprule
    Malware Families \\
    \midrule
	legit \\
	cryptolocker \\
	zeus \\
	pushdo \\
	rovnix \\
	tinba \\
	conficker \\
	matsnu \\
	ramdo \\
	\bottomrule
\end{tabular}
\caption{\label{tab:malware}}
\end{table}

I risultati della predizione sul subset di testing sono mostrati in figure~\ref{fig:repdga},~\ref{fig:repsvc},~\ref{fig:repgnb}. A fianco dell'etichette \textit{legit} e \textit{DGA} è indicato il numero di campioni utilizzati per le due categorie. Come si può notare la performance del Classificatore Machine Learning è molto positiva, mostrando valori pari al 99\% in tutte le categorie di valutazione.  Si ipotizza che tale risultato sia dovuto alla forte differenza linguistica tra domini reali e domini DGA; pertanto il classificatore soffre di un errore praticamente nullo. 

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_nosup_nosup/class_rep.png}
    \caption{Report di classificazione algoritmo Random Forest.\label{fig:repdga}}
\end{figure}

I classificatori SVC e Naive Bayes non hanno mostrato risultati altrettanto eccellenti. In particolare SVC ha dimostrato una recall sui domini reali molto bassa, pari al 30\%; mentre lo stesso valore per i DGA è eccellente. Anche il valore di precision rispetto ai DGA è decisamente inferiore rispetto al Classificatore Machine Learning, infatti si attesta ad un valore del 70\%. Il valore di F-Score, che mostra una media dell'andamento del classificatore, mostra un basso valore per quel che riguarda i domini reali: 45\% ed un valore appena sufficiente per domini DGA: 82\%.
Il classificatore Naive Bayes si piazza a metà tra i due casi precedenti, mostrando buoni risultati nel caso di DGA (Precision 96\%, Recall 91\%) e risultati intermedi per quel che riguarda i domini reali (Precision 87\% e Recall 93\%). A causa di questi risultati si è deciso di proseguire il resto del lavoro utilizzando Random Forest, dati gli eccellenti risultati nelle condizioni di esperimento più semplici. 
In figura~\ref{fig:rocdga} è possibile vedere la curva ROC per il cassificatore Random Forest per l'esperimento in questione, confermando i risultati precedenti, con un'area sottesa dalla curva approssimata ad 1.00.

\begin{figure}[!bp]
  	\centering
    \includegraphics[width=\columnwidth]{figures/report_SVC.png}
    \caption{Report di classificazione per l'algoritmo SVC.\label{fig:repsvc}}
	\hfill
	\vspace{3cm}
	\centering
    \includegraphics[width=\columnwidth]{figures/report_GaussianNB.png}
    \caption{Report di classificazione per l'algoritmo Naive-Bayes.\label{fig:repgnb}}
\end{figure}

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_nosup_nosup/roc_plot.png}
    \caption{Classificatore Machine Learning: Area sottesa dalla curva ROC per il test con domini di tabella~\ref{tab:malware}.\label{fig:rocdga}}
\end{figure}

\newpage
\subsection{Caso Suppobox}
Il classificatore Machine Learning è stato successivamente testato inserendo \textit{suppobox} tra le famiglie DGA già presenti. Si è scelto tale malware come campione esterno in quanto presenta la maggiore differenza rispetto alle famiglie mostrate in tabella~\ref{tab:malware}. I risultati si possono vedere in figura~\ref{fig:repsup} e~\ref{fig:rocsup} e come si può notare la performance ne è fortemente influenzata, introducendo una grande percentuale di falsi nelle predizioni effettuate dal classificatore. In particolare si può vedere come sia nel caso dei domini reali la performance di precision è fortemente peggiorata (Precision 20\%) oltre che la Recall nel caso DGA (Recall 14\%). In generale il classificatore dimostra una performance media data dall'F-score del 33\% e 24\%. 
La ROC conferma i risultati precedenti, mostrando un'area sottesa dalla curva di 0.45, inferiore al caso ( indicato dalla linea tratteggiata rossa) in figura~\ref{fig:rocsup}. La causa di tale risultato è da ricercarsi nell'algoritmo di generazione dei domini di suppobox, in quanto utilizza due parole ottenute dal dizionario inglese per formare in maniera pseudorandomica i domini. Tale tecnica quindi produce stringhe formate da parole leggibili, solitamente caratteristica dei domini reali provenienti da Alexa. Il classificatore risulta quindi in difficoltà nel discriminare domini reali e domini DGA per questo motivo.

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_nosup_sup/class_rep.png}
    \caption{Classificatore Machine Learning: Report di classificazione su un subset di domini reali (legit) e malware, comprendenti suppobox (DGA).\label{fig:repsup}}

    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_nosup_sup/roc_plot.png}
    \caption{Classificatore Machine Learning: Area sottesa dalla curva ROC per il test con  suppobox.\label{fig:rocsup}}
\end{figure}

Come ultimo test è stato eseguito il training aggiungendo al precedente subset una parte di domini generati da suppobox (Figura~\ref{fig:repall} e~\ref{fig:rocall}). Come si può notare la performance è migliorata sensibilmente, non raggiungendo comunque i risultati eccellenti del primo test, con valori per i domini reali di Precision 94\% e Recall 88\% e rispetto ai domini DGA di precision 89\% e 92\%.
L'area sottesa dalla ROC è di 0.97, mostrando un risultato generalmente accettabile per un utilizzo reale.

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_sup_sup/class_rep.png}
    \caption{Classificatore Machine Learning: Report di classificazione su un subset di domini reali (legit) e malware, comprendenti suppobox (DGA).\label{fig:repall}}

    \centering
    \includegraphics[width=\columnwidth]{figures/rndf_tra_sup_sup/roc_plot.png}
    \caption{Classificatore Machine Learning: Area sottesa dalla curva ROC per il test con domini reali e malware (comprendenti suppobox).\label{fig:rocall}}
\end{figure}

\newpage
\section{Classificatore Neurale}
\label{ris:cnn}
Il classificatore neurale, nato per superare la performance del classificatore Machine Learning, è stato testato nelle stesse condizioni utilizzate precedentemente: in particolare è stato utilizzato lo stesso dataset mostrato in sezione~\ref{res:crf} e diviso in $\frac{9}{10}$ come subset di training e $\frac{1}{10}$ come subset di testing.

In prima fase si sono messe a confronto le tre architetture presentate in sezione~\ref{classificatorenninterno}. Tali architetture hanno dimostrato tre andamenti simili; tuttavia a fronte dei risultati mostrati e della minore richiesta di risorse, il modello intermedio è risultato vincente rispetto agli altri testati. In Figura~\ref{fig:cfrmlp} è possibile vedere un confronto tra i tre modelli: la curva di colore grigio rappresenta il modello ingrandito, la curva di colore arancione rappresenta il modello ridotto mentre la curva di colore rosso rappresenta il modello intermedio; vincente tra i tre, mostrando una accuracy mediamente migliore del 8\% ed una Loss inferiore del 22\%. Tale risultato è da attestarsi nella conformazione dell'architettura degli strati del classificatore neurale. Infatti il modello ridotto non è in grado di cogliere le caratteristiche dei domini in maniera efficiente, mentre il modello allargato non riesce a produrre un vettore di features significativo a causa del numero troppo ampio di strati nascosti che lo compongono.

\begin{figure}[!bp] 
\centering
	\begin{minipage}[t]{\linewidth}
		\includegraphics[width=\linewidth]{figures/MLP1.png}
	\end{minipage}\hfill
	\vspace{3cm}
	\begin{minipage}[b]{\linewidth}
		\includegraphics[width=\linewidth]{figures/MLP2.png}
	\end{minipage}
	\caption{Classificatore Neurale: Grafici di Accuracy e Loss in funzione del tempo durante la fase di training. confronto fra i tre modelli. \label{fig:cfrmlp}}
\end{figure}

\newpage
\subsection{Batch Normalization}
Motivo di indagine è stata l'introduzione o meno di Batch Normalization~\cite{1502.03167}. Come si può vedere dai grafici mostrati in figura~\ref{fig:batchnorm} vi è un miglioramento delle prestazioni di circa il 4\% dovuto alla normalizzazione dei mini-batch, pertanto si è scelto di mantenere tale funzione all'interno dei livelli nonostante l'aumento di costi prestazionali. La curva rossa identifica il modello senza l'ausilio di Batch Normalization mentre la curva fuchsia rappresenta lo stesso modello con l'inserimento di Batch Normalization per ogni livello densamente connesso che compone il Multilayer Perceptron.

\begin{figure}[!bp] 
	\begin{minipage}[t]{\linewidth}
		\includegraphics[width=\linewidth]{figures/MLP_batchnorm1.png}
	\end{minipage}
	\begin{minipage}[b]{\linewidth}
		\includegraphics[width=\linewidth]{figures/MLP_batchnorm2.png}
	\end{minipage}
	\caption{Classificatore Neurale: Grafici di Accuracy e Loss in funzione del tempo per il modello intermedio durante la fase di training. \label{fig:batchnorm}}
\end{figure}

\newpage
\subsection{Iperparmetri}
Particolare attenzione ha richiesto il tuning degli iperparametri di numero epoche e dimensione mini-batch per ottenere valori ottimali. Dopo una serie di test sperimentali che hanno messo a confronto diversi valori, si sono rilevati i valori:

\begin{itemize}
\item \textbf{numero epoche} $= 60$
\item \textbf{dimensione minibatch} $= 35$ 
\end{itemize}

Tali valori hanno dimostrato di fornire la migliore performance durante la fase di training.

I test effettuati sul dataset hanno mostrato i risultati mostrati in figura~\ref{fig:cnrepall} e~\ref{fig:cnrocall}. Come si può vedere dai grafici il comportamento del classificatore è pressoché identico a quello mostrato dal Classificatore Machine Learning (figure~\ref{fig:repall} e~\ref{fig:rocall} )

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/clas_nn/class_rep.png}
    \caption{Classificatore Neurale: Report di classificazione su un subset di domini reali (legit) e malware, comprendenti suppobox (DGA).\label{fig:cnrepall}}
\end{figure}

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/clas_nn/roc_plot.png}
    \caption{Classificatore Neurale: Area sottesa dalla curva ROC per il test con domini reali e malware (comprendenti suppobox).\label{fig:cnrocall}}
\end{figure}

\newpage
\section{Autoencoder}
\label{ris:autoenc}
L'Autoencoder come presentato in sezione~\ref{autoencoder} è stato testato con il dataset mostrato in sezione~\ref{imp:autoencoder:dataset}. In fase sperimentale si è proceduto alla quantificazione della configurazione ottimale dell'Autoencoder. In particolare si sono messi a confronto i valori di dropout presenti all'interno di encoder e decoder ed i valori di learning rate dei rispettivi compilatori. I valori finali di tali compilatori sono indicati all'interno della sezione~\ref{imp:autoe:enc} e~\ref{imp:autoe:dec}

In figura~\ref{fig:aut1} è possibile notare i risultati della fase di training, per il quale si è trattenuto $\frac{1}{3}$ del training set come subset di validazione.  La prima fase è rappresentata dalla curva arancione, la seconda dalla curva fuchsia mentre la terza fase è rappresentata dalla curva di colore verde. Si può notare come la terza iterazione raggiunga valori di accuracy e loss  nettamente migliori; pertanto stato scelto come configurazione vincente per la GAN.

\begin{figure}[!bp]
    \centering
    \begin{minipage}[t]{\linewidth}
    	\includegraphics[width=\linewidth]{figures/autoenc.png}
    \end{minipage}\hfill
    \begin{minipage}[b]{\linewidth}
    	\includegraphics[width=\linewidth]{figures/autoenc2.png}
    \end{minipage}
    \caption{Grafici di Accuracy e Loss in funzione del tempo per la fase di training dell'Autoencoder. \label{fig:aut1}}
\end{figure}

In figura~\ref{fig:aut2} è possibile vedere i grafici dei valori di accuracy e loss in funzione del tempo durante la fase di testing dell'Autoencoder.  La prima fase è rappresentata dalla curva arancione, la seconda dalla curva fuchsia mentre la terza fase è rappresentata dalla curva di colore verde. Si può notare come i valori raggiunti siano molto simili a quelli ottenuti sul dataset di training, indice di qualità del modello rispetto a valori mai visti.

\begin{figure}[!bp]
    \centering
    \begin{minipage}[t]{\linewidth}
    	\includegraphics[width=\linewidth]{figures/autoenc3.png}
    \end{minipage}
    \begin{minipage}[b]{\linewidth}
    	\includegraphics[width=\linewidth]{figures/autoenc4.png}
    \end{minipage}
    
\caption{Grafici di Accuracy e Loss in funzione del tempo rispetto al subset di validazione dell'Autoencoder. \label{fig:aut2} }
\end{figure}

\newpage
\subsection{Generazione Domini}
In tabella~\ref{tab:autoenc} è possibile vedere un esempio di quali domini l'Autoencoder produce dato un subset del dataset Alexa in input. Si può notare come siano vagamente simili ai domini reali per quanto riguarda la distribuzione dei caratteri e la lunghezza media dei domini, tuttavia non presenta ulteriori caratteristiche tali da influenzare negativamente i classificatori neurali.

\begin{table}[!bp]
\centering
	\begin{tabular}{l}
	\toprule
	ehyt5tcncn3o5nw \\
	reknclkobg \\
	kne3xersl6npyr5 \\
	moeaamutlrhsn \\
	5t7-iitnvtrm5en \\
	r-zeotn0t-wuf \\
	bgargtas \\
	vviadammpielw \\
	7-aolelcfiextl \\
	morehekb \\
	d9ongedeo  \\
	meoomer \\
	zggy1lbxgi1psir \\
	ypsanilwrox \\
	bt5ennsl1zjchp0 \\
	runvpfcfrmaser \\
	anhgnxracokimoa \\
	atngsam \\
	de-poaz9yiiu \\
	nhntadt \\
	\bottomrule
	\end{tabular}
	\begin{tabular}{l}
	\toprule
	2kbth \\
	snd-drcepn \\
	sievd0 \\
	ono5ponlanafhic \\
	mmd0-5-ile \\
	su1aojp52 \\
	eraveok \\
	lfeubune \\
	ilnegban0 \\
	uim-rca0ohxmsbi \\
	oldohizlioczzu \\
	dodttiune \\
	ahoinin3 \\
	etiso9oo \\
	qi8gtuyte-ssg-n \\
	mlsrp8gf \\
	ktb1r2vb \\
	ptsdrqtanflog \\
	mcng5tsotnless \\
	rrhtsrceu \\
	\bottomrule
	\end{tabular}
\caption{Esempio di domini generati dall'Autoencoder. \label{tab:autoenc}}
\end{table}

\newpage
L'utilizzo dei pesi dell'Autoencoder come punto di partenza per il training della GAN ha contribuito fortemente a ridurre la instabilità di tale sistema, permettendo ai due sottosistemi generatore e discriminatore di partire da predizioni più precise rispetto all'utilizzo di pesi inizializzati in maniera casuale come generalmente attuato.


\newpage
\section{Generative Adversarial Network}
\label{ris:gan}
La Generative Adversarial Network descritta in sezione~\ref{ganintro} e implementata come in sezione~\ref{imp:gan} ha richiesto una lunga fase sperimentale nella quale è stato necessario trovare la giusta combinazione di iperparametri per i quali i due sottosistemi generatore e discriminatore potessero rimanere in equilibrio durante la durata necessaria per completare la fase di training. 

In particolare si sono incontrati due \textit{failure modes}:
\begin{itemize}
\item Caso in cui il discriminatore prevale sul generatore, come mostrato in figura~\ref{fig:ganfailure1}, si ottiene una curva di \textit{loss} rasente lo zero, causando al generatore un incremento costante della propria curva di loss. Il significato di tale comportamento è l'impossibilità del generatore di generare domini sintetici sufficientemente realistici da poter mettere in crisi la predizione del discriminatore.
\item Caso in cui il generatore degeneri, producendo "spazzatura", rendendo eccessivamente semplice la predizione del discriminatore. La degenerazione infatti avviene in forma di domini generati tutti uguali, contenente una singola lettera ripetuta per tutta la lunghezza di caratteri. Tale comportamento è dovuto alla mancata capacità del generatore di mimare realisticamente i domini realistici. Un esempio di tale comportamento è mostrato in figura~\ref{fig:ganfailure2}
\end{itemize}

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/gan/ganfailure1.png}
    \caption{Caso di degenerazione 1. Grafico del valore di loss in funzione del tempo. Il discriminatore (curva di colore grigio) prevale sul generatore (curva arancione), il quale non riesce a migliorare il proprio valore di loss.\label{fig:ganfailure1}}
	\vspace{3cm}
    \centering
    \includegraphics[width=\columnwidth]{figures/gan/ganfailure2.png}
    \caption{Caso di degenerazione 2. Grafico del valore di loss in funzione del tempo. Il generatore (curva di colore azzurro) non produce domini realistici, degenerando a dati inutilizzabili. Il discriminatore (curva di colore rosso) di conseguenza migliora la propria loss a causa della differenza sempre maggiore tra domini realistici e domini sintetici. \label{fig:ganfailure2}}
\end{figure}

\`E stato possibile ottenere la stabilità della GAN, grazie a numerose tecniche empiriche ottenute da~\cite{1606.03498} ed all'utilizzo del pre-training fornendo come inizializzazione i pesi ottenuti dalla fase di training dall'Autoencoder. In figura~\ref{fig:ganok} si può vedere l'andamento dei valori di loss di generatore e discriminatore nel caso di equilibrio tra le due reti neurali.

\begin{figure}[!bp]
\centering
\includegraphics[width=\columnwidth]{figures/gan/ganok.png}
\caption{Grafico di loss in funzione del tempo per discriminatore (curva di colore rosso) e generatore (curva di colore azzurro). L'andamento rimane equilibrato fino al punto in cui il generatore non riesce a generare nuovi domini in grado di mettere in crisi il discriminatore. \label{fig:ganok}}
\end{figure}

Grazie a tale training è stato possibile infine generare un dataset di domini sintetici provenienti dalla GAN, che mimassero in maniera più precisa i domini realistici. Come si può notare in tabella~\ref{tab:gan} non si tratta di una rappresentazione di parole realmente esistenti, tuttavia si può notare come siano presenti n-grammi realmente esistenti oltre che ad una lunghezza di sequenza simile a domini reali.

\begin{table}[!bp]
\centering
	\begin{tabular}{l}
	\toprule
edarareve \\
skonasesosarere \\
skaran-unar \\
chicochophavock \\
dichoros \\
isherevores \\
nillersosersrsp \\
rldicde \\
escrarararuro \\
aemjtup \\
	\bottomrule
	\end{tabular}
	\begin{tabular}{l}
	\toprule
	ssrarsone \\
asccacca \\
monasheamc \\
itsusosose \\
stlega \\
ivortewrp \\
sdesedlsss \\
nggeneneres \\
madesadk \\
cesasasrrrrrrs \\
	\bottomrule
	\end{tabular}
	\begin{tabular}{l}
	\toprule
	horicicocr \\
sthonacorl \\
raocjcacarcrarl \\
vichitos \\
ogagagasuss \\
plerundinwoshn \\
odocococcocke \\
tuccronpcs \\
mivorthitdhud \\
mtuvocaro \\
	\bottomrule
	\end{tabular}
	\begin{tabular}{l}
	\toprule
avensdends \\
mwonwonerene \\
inihkkellgcrock \\
madoxto \\
ljarlers \\
maahofononoris \\
msusongere \\
scsacccca \\
rrngajiagjonggk \\
ituutasisa \\
	\bottomrule
	\end{tabular}

\caption{Esempio di domini generati dalla GAN. \label{tab:gan}}
\end{table}

Come si può notare dal confronto mostrato in figura~\ref{fig:chardistr} la distribuzione dei caratteri generata dalla GAN è molto simile a quella presente all'interno del dataset Alexa, dimostrando la natura dei domini sintetici rispetto a quelli reali.

\begin{figure}[!bp]
    \centering
    \begin{minipage}[t]{\columnwidth}
    \centering
		\includegraphics[width=0.85\linewidth]{figures/all_legit_char_distr.png} \\
		Distribuzione caratteri dei domini reali.
	\end{minipage}\hfill
	\vspace{1cm}
	\begin{minipage}[b]{\columnwidth}
	\centering
		\includegraphics[width=0.85\linewidth]{figures/chars_histogram.png} \\
		Distribuzione dei caratteri dei domini generati dalla GAN.
	\end{minipage}
\caption{Confronto distribuzioni di caratteri \label{fig:chardistr}}
\end{figure}

\newpage
\subsection{Test su Classificatore Neurale}
Il classificatore neurale presentato in sezione~\ref{classificatorenn} è stato messo alla prova utilizzando un subset circa 10000 domini generati dalla GAN, etichettati come DGA, ed un subset di 10000 domini reali provenienti dal dataset Alexa. 
Come si può vedere da figura~\ref{fig:repgan} il classificatore si trova in grave difficoltà nel distinguere i domini DGA, raggiungendo un bassissimo valore di recall pari al 12\% e ad un valore medio di precision su entrambe le categorie di domini pari a 54\%. Lo F-Score medio del classificatore ne risulta molto basso rispetto a quello precedentemente mostrato in figura~\ref{fig:cnrepall}, con valori per i domini reali del 67\% e per domini DGA del 19\%.
In figura~\ref{fig:rocgan} è mostrata la curva ROC del classificatore neurale testato nelle medesime condizioni: la ridottissima area sottesa pari a 0.39 dimostra come il classificatore non sia in grado di distinguere in maniera efficiente i domini reali da quelli generati dalla GAN. 

Tali risultati a confronto con quelli mostrati in sezione~\ref{res:crf} e~\ref{ris:cnn} dimostrano come i domini sintetici generati dalla GAN siano in grado di influenzare negativamente la performance di un classificatore DGA che in precedenza ha dimostrato buoni risultati. La causa di tale risultato è da ricercarsi nella conformazione dei domini, formati a partire da quelli reali e quindi in grado di mimare le caratteristiche linguistiche fondamentali che il classificatore neurale estrae per effettuare la discriminazione.

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/gan/class_rep.png}
    \caption{Classificatore Neurale testato su GAN: Report di classificazione su un subset di domini reali (legit) e generati da GAN (DGA).\label{fig:repgan}}
\end{figure}

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/gan/roc_plot.png}
    \caption{Classificatore Neurale: Area sottesa dalla curva ROC per il test con domini reali e generati da GAN.\label{fig:rocgan}}
\end{figure}

\newpage
\subsection{Rafforzamento Classificatore Neurale}
In ultima fase si è proceduto al training del classificatore utilizzando il dataset mostrato in sezione~\ref{res:crf} con l'aggiunta dei domini generati dalla GAN a far parte del training set. Anche in questo caso è stato diviso in $\frac{9}{10}$ per la fase di training e $\frac{1}{10}$ per la fase di testing.
I risultati mostrati in figura~\ref{fig:repnngan} mostrano come il classificatore mostri una migliorata robustezza rispetto ai domini generati (Precision 90\% e Recall\%92) sia rispetto ai domini reali (Precision 92\% e Recall 88\%). Confrontando i risultati con l'esperimento precedente, ovvero senza allenamento (Figura~\ref{fig:repgan}) vi è un incremento delle prestazioni di circa il 74\% per quanto riguarda la Precision rispetto ai domini reali, e del 61\% per quanto riguarda la Precision dei domini generati. Tuttavia la metrica Recall rispetto ai domini reali è decrementata del 4\% mentre aumentata dell'667\% per i domini generati. Valutando la prestazione media, tramite F-Score, si nota come il classificatore risulti la propria prestazione incrementata del 34\% per domini reali e del 379\% per domini generati. 
Anche Rispetto al valore dell'area sottesa dalla ROC vi è un incremento di prestazione sostanziale, ottenendo una AUC di 0.98, con un aumento di valore del 158\% rispetto al caso precedente.

Il classificatore così rafforzato tramite Adversarial Examples presenta un comportamento molto più stabile rispetto ai domini generati da GAN ed un  lieve incremento di prestazioni rispetto ai risultati mostrati in sezione~\ref{ris:cnn}. In particolare si mostra un incremento dell'1\% per i domini reali, sia nel caso di Precision che Recall mentre nel caso di domini DGA si è visto solamente un incremento del 2\% per quel che riguarda la Precision. In media il classificatore ha mostrato un incremento di prestazioni del 1\% rispetto ai domini reali, ma dimostra comunque una migliorata stabilità rispetto a casi mai visto come i domini generati dalla GAN.

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/classreff/class_rep.png}
    \caption{Classificatore Neurale allenato su GAN: Report di classificazione su un subset di domini reali (legit) e generati da GAN (DGA).\label{fig:repnngan}}
\end{figure}

\begin{figure}[!bp]
    \centering
    \includegraphics[width=\columnwidth]{figures/classreff/roc_plot.png}
    \caption{Classificatore Neurale: Area sottesa dalla curva ROC per il test con domini reali e generati da GAN.\label{fig:rocnngan}}
\end{figure}

\newpage
\section{Valutazione Risultati}
I Risultati mostrati nelle sezioni precedenti hanno mostrato interessanti caratteristiche. 
\begin{itemize}
\item Il progetto del classificatore Machine Learning ha dimostrato di essere sufficientemente stabile discriminare con buonissima approssimazione i DGA generati dalla stragrande maggioranza dei malware odierni. 

\item Il caso particolare di Suppobox ha tuttavia ridotto la capacità del classificatore di una percentuale considerevole, ed anche l'architettura alternativa ideata tramite reti neurali non ha sortito l'effetto sperato e recuperato la prestazione perduta. 
Tale risultato negativo è forse migliorabile utilizzando un'architettura di rete neurale più evoluta, ad esempio tramite l'utilizzo di una Rete Convoluzionale, in grado di eseguire una più precisa rilevazione delle caratteristiche fondamentali che compongono i domini.

\item Successivamente si è utilizzato l'Adversarial Learning per rafforzare il classificatore rispetto a casi non ancora esistenti. L'obiettivo di generare domini realistici tramite l'utilizzo di una GAN è stato in parte raggiunto. I domini generati dimostrano alcune caratteristiche linguistiche proprie dei vocaboli reali ma tuttavia sono ancora distinguibili dal subset reale utilizzato dai classificatori.
Tale risultato in parte negativo ha comunque dimostrato di mettere in crisi la performance del classificatore neurale durante la fase di testing.

\item Il classificatore neurale successivamente riallenato aggiungendo l'insieme dei domini generati dalla GAN nel subset di training, non ha mostrato i miglioramenti sperati in fase progettuale, ma tuttavia ha dimostrato robustezza nei confronti degli stessi domini.
\end{itemize}